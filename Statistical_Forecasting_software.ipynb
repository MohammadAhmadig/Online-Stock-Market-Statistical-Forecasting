{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import lightgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import glob\n",
    "import functools\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "def Forecast(ndata, method):\n",
    "\n",
    "    if(method == 'AR'):\n",
    "        # fit model\n",
    "        model = AutoReg(ndata, lags=1,old_names=False)\n",
    "        model_fit = model.fit()\n",
    "        # make prediction\n",
    "        yhat = model_fit.predict(len(ndata), len(ndata))\n",
    "    elif(method == 'MA'):\n",
    "        # fit model\n",
    "        model = ARIMA(ndata, order=(0, 0, 1))\n",
    "        model_fit = model.fit()\n",
    "        # make prediction\n",
    "        yhat = model_fit.predict(len(ndata), len(ndata))\n",
    "    elif(method == 'ARMA'):\n",
    "        # fit model\n",
    "        model = ARIMA(ndata, order=(2, 0, 1))\n",
    "        model_fit = model.fit()\n",
    "        # make prediction\n",
    "        yhat = model_fit.predict(len(ndata), len(ndata))\n",
    "    elif(method == 'ARIMA'):\n",
    "        # fit model\n",
    "        model = ARIMA(ndata, order=(1, 1, 1))\n",
    "        model_fit = model.fit()\n",
    "        # make prediction\n",
    "        yhat = model_fit.predict(len(ndata), len(ndata), typ='levels')\n",
    "    elif(method == 'SARIMA'):\n",
    "        # fit model\n",
    "        model = SARIMAX(ndata, order=(1, 1, 1), seasonal_order=(0, 0, 0, 0))\n",
    "        model_fit = model.fit(disp=False)\n",
    "        # make prediction\n",
    "        yhat = model_fit.predict(len(ndata), len(ndata))\n",
    "    elif(method == 'SARIMAX'):\n",
    "        # fit model\n",
    "        model = SARIMAX(ndata, exog=exogdata, order=(1, 1, 1), seasonal_order=(0, 0, 0, 0))\n",
    "        model_fit = model.fit(disp=False)\n",
    "        # make prediction\n",
    "        yhat = model_fit.predict(len(ndata), len(ndata), exog=[6])\n",
    "    elif(method == 'VARMAX'):\n",
    "         print('varmax')\n",
    "    elif(method == 'SES'):\n",
    "        # fit model\n",
    "        model = SimpleExpSmoothing(ndata)\n",
    "        model_fit = model.fit()\n",
    "        # make prediction\n",
    "        yhat = model_fit.predict(len(ndata), len(ndata))\n",
    "    elif(method == 'HWES'):\n",
    "        # fit model\n",
    "        model = ExponentialSmoothing(ndata)\n",
    "        model_fit = model.fit()\n",
    "        # make prediction\n",
    "        yhat = model_fit.predict(len(ndata), len(ndata))\n",
    "    \n",
    "    return yhat\n",
    "\n",
    "def LightGBM():\n",
    "    \n",
    "    #lightgbm regression\n",
    "    row_count2 = x_train.shape[0]\n",
    "    split_point2 = int(row_count2*test_ratio)\n",
    "    X, X_test = x_train[:split_point2], x_train[split_point2:]\n",
    "    Y, Y_test = y_train[:split_point2], y_train[split_point2:]\n",
    "    train_data = lightgbm.Dataset(X, label=Y)\n",
    "    test_data = lightgbm.Dataset(X_test, label=Y_test)\n",
    "    parameters = {'objective': 'regression',\n",
    "              'boosting': 'gbdt',\n",
    "              'metric': 'rmse',\n",
    "              'learning_rate': 0.1,\n",
    "              'seed' : 42}\n",
    "    model = lightgbm.train(parameters,\n",
    "                           train_data,\n",
    "                           valid_sets=test_data,\n",
    "                           num_boost_round=5000,\n",
    "                           early_stopping_rounds=100)\n",
    "    return model\n",
    "\n",
    "def LR():\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(x_train, y_train)\n",
    "    return reg\n",
    "\n",
    "def date(d,cv_type):\n",
    "    if(cv_type =='last 5%'):\n",
    "        rcount = d.shape[0]\n",
    "        splitpoint = int(rcount*test_ratio)\n",
    "        xtest = d[splitpoint:]\n",
    "        return xtest.Date\n",
    "        \n",
    "    else:#-----\n",
    "        rcount = d.shape[0]\n",
    "        splitpoint = int(rcount*test_ratio)\n",
    "        xtest = d[splitpoint:]\n",
    "        return xtest.Date\n",
    "    \n",
    "def make_sliding(df, N):\n",
    "    dfs = [df.shift(-i).applymap(lambda x: [x]) for i in range(0, N+1)]\n",
    "    return functools.reduce(lambda x, y: x.add(y), dfs)\n",
    "\n",
    "prior_file_dict = dict()\n",
    "test_ratio = 85/100 # 1 %\n",
    "#while(1):\n",
    "    \n",
    "file_dict = dict()\n",
    "# Load data\n",
    "extension = 'csv'\n",
    "files = glob.glob('*.{}'.format(extension))\n",
    "files = [ x for x in files if \".ai\" not in x ]\n",
    "#for file in files:# files without .ai name\n",
    "#    if('.ai' in file):\n",
    "#        files.remove(file)\n",
    "\n",
    "# files is empty\n",
    "if not files:\n",
    "    print('No csv File seen.')\n",
    "    #break\n",
    "    sys.exit()\n",
    "\n",
    "targets = [' ZigZag Value']\n",
    "regression_names = ['LinearRegression','Lightgbm']\n",
    "forecast_names = ['AR','MA','ARMA','ARIMA','SARIMA','SARIMAX','SES','HWES']\n",
    "#forecast_names = ['AR']\n",
    "#forecast_names = ['MA']\n",
    "#result_file = pd.DataFrame(columns = ['File_Name','LiteGBM', 'LR','AR','MA','ARMA','ARIMA','SARIMA','SES','HWES','Rank'])\n",
    "result_file = pd.DataFrame(columns = ['File_Name','AR','MA','ARMA','ARIMA','SARIMA','SARIMAX','SES','HWES','LinearRegression','Lightgbm','best'])\n",
    "#result_file = pd.DataFrame(columns = ['File_Name','AR','best'])\n",
    "\n",
    "for j in range(len(files)):\n",
    "    data = pd.read_csv(files[j], parse_dates=['Date'])\n",
    "    tempdata = pd.read_csv(files[j])\n",
    "    \n",
    "    #test_date\n",
    "    test_date = date(tempdata,'last 5%')\n",
    "    # new features\n",
    "    data['month'] = data.Date.dt.month\n",
    "    #data['week'] = data.Date.dt.week\n",
    "    data['week_day'] = data.Date.dt.weekday\n",
    "    data['year'] = data.Date.dt.year\n",
    "    data['days_in_month'] = data.Date.dt.days_in_month\n",
    "    data = data.drop(\"Date\", axis=1)\n",
    "\n",
    "    #results = pd.Series()\n",
    "    #results = np.append(results, files[j])\n",
    "    results = pd.DataFrame(columns = ['File_Name','AR','MA','ARMA','ARIMA','SARIMA','SARIMAX','SES','HWES','LinearRegression','Lightgbm','best'])\n",
    "    #results = pd.DataFrame(columns = ['File_Name','AR','best'])\n",
    "    results = results.append(pd.Series(), ignore_index=True)\n",
    "    results.File_Name = files[j]\n",
    "    \n",
    "    file_dict[files[j]] = data.shape[0]\n",
    "    if files[j] not in prior_file_dict:\n",
    "\n",
    "        text = \"\"\n",
    "        for target in targets:\n",
    "            x_data = data.loc[:,data.columns != target]\n",
    "            y_data = data[target]\n",
    "\n",
    "            # test 15 % last\n",
    "            row_count = data.shape[0]\n",
    "            split_point = int(row_count*test_ratio)\n",
    "            x_train, x_test = x_data[:split_point], x_data[split_point:]\n",
    "            y_train, y_test = y_data[:split_point], y_data[split_point:]\n",
    "\n",
    "            #-----------------\n",
    "            temp_error = x_test[' ZigZag Length'].mean()/100000\n",
    "            for forecast_name in forecast_names:\n",
    "                new_data = y_train\n",
    "                exogdata = x_train['week_day']\n",
    "                \n",
    "                y_pred = pd.Series()\n",
    "                for m in range(row_count - split_point):# predict next test data\n",
    "                    #ai_predicted.loc[ai_predicted.shape[0]-1,'Date'] = tempdata.Date[prior_file_dict[files[j]]+count] # add Date\n",
    "\n",
    "\n",
    "                    # predict next value\n",
    "                    if(target == ' ZigZag Value'):\n",
    "                        #mdl = LinearRegression()\n",
    "                        #mdl.fit(x_train, y_train)\n",
    "                        y_hat = Forecast(new_data,forecast_name)\n",
    "                    else:\n",
    "                        train_data = lightgbm.Dataset(X, label=Y)\n",
    "                        test_data = lightgbm.Dataset(X_test, label=Y_test)\n",
    "                        parameters = {'objective': 'regression','boosting': 'gbdt','metric': 'rmse','learning_rate': 0.1,'seed' : 42}\n",
    "                        mdl = lightgbm.train(parameters,train_data,valid_sets=test_data,num_boost_round=5000,early_stopping_rounds=100)\n",
    "                        #mdl = regressions[1]\n",
    "                    #y_pred = y_pred.append(mdl.predict(x_test2))\n",
    "                    #ttemp = mdl.predict(x_test2)\n",
    "                    y_pred = np.append(y_pred, y_hat)\n",
    "                    #x_test3.c14 = y_pred2[0]\n",
    "                    #y_pred3 = mdl.predict(x_test3)\n",
    "                    #if(target == 'ZigZag'):\n",
    "                    #    next_zigzag2 = y_pred2\n",
    "                        #next_zigzag3 = y_pred3\n",
    "\n",
    "                    new_data = np.append(new_data, y_test[y_test.index[0]+m])\n",
    "                    exogdata = np.append(exogdata, x_test['week_day'][x_test.index[0]+m])\n",
    "                    \n",
    "                #temp_y_test= y_test.to_numpy()\n",
    "                #percent_error = (abs((y_pred[1:])-(temp_y_test[:-1])) / abs((temp_y_test[1:])-(temp_y_test[:-1])) ) *100\n",
    "                #percent_error = [ x for x in percent_error if np.isfinite(x)]\n",
    "                #percent_error = np.mean(percent_error)\n",
    "                #results[forecast_name]= percent_error # mean\n",
    "                \n",
    "                #percent_error= ((abs(y_test - y_pred) / abs(y_test))*100)\n",
    "                #percent_error = np.mean(percent_error)\n",
    "                #results[forecast_name]= percent_error # mean\n",
    "                #results = np.append(results, np.mean(percent_error))\n",
    "                rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "                percent_error = (rmse/temp_error)*100\n",
    "                results[forecast_name]= percent_error # mean\n",
    "                if(target == ' ZigZag Value'):\n",
    "                    zigzag = y_pred\n",
    "                elif(target == 'ZigZag Length'):\n",
    "                    zigzaglength = y_pred\n",
    "                #percent_error= ((abs(y_test - y_pred) / abs(y_test))*100) \n",
    "                #percent_error = percent_error.mean()\n",
    "                print(\"RMSE = \" , rmse)\n",
    "                text = text + \"\\nRoot mean squared error for \"+ forecast_name +' for '+target +\" = \" + str(rmse) +\"\\n\"\n",
    "                text = text +'---------------------------------------------------------'\n",
    "                text = text + \"\\nPercent error for \"+  forecast_name +' for ' + target +\" = \" + str(percent_error) +\"\\n\"\n",
    "                text = text +'---------------------------------------------------------'\n",
    "            \n",
    "            #-----------------\n",
    "            for ii in range(2):\n",
    "                new_data = data[:split_point] \n",
    "                window_size = 14\n",
    "                x = make_sliding(new_data,window_size)\n",
    "                x = x.loc[:,new_data.columns == target]\n",
    "                x[['c1','c2','c3','c4','c5',\n",
    "                   'c6','c7','c8','c9','c10',\n",
    "                   'c11','c12','c13','c14','c15']] = pd.DataFrame(x[target].tolist(), index= x.index)\n",
    "                x = x.drop(target, axis=1)\n",
    "                #x_test3 = x[x.shape[0]-window_size+1:x.shape[0]-window_size+2]\n",
    "                x = x[:x.shape[0]-window_size+1]\n",
    "\n",
    "                y_pred = pd.Series()\n",
    "                for m in range(row_count - split_point):# predict next test data\n",
    "                    #ai_predicted.loc[ai_predicted.shape[0]-1,'Date'] = tempdata.Date[prior_file_dict[files[j]]+count] # add Date\n",
    "\n",
    "\n",
    "                    # predict next value\n",
    "\n",
    "                    x_test2 = x[x.shape[0]-1:].drop(\"c15\", axis=1)\n",
    "                    #x_test3 = x_test3.drop(\"c15\", axis=1)\n",
    "                    train2 = x[:x.shape[0]-1]\n",
    "                    y_train = train2.c15\n",
    "                    x_train = train2.drop(\"c15\", axis=1)\n",
    "\n",
    "                    # validation of lightgbm\n",
    "                    row_count2 = x_train.shape[0]\n",
    "                    split_point2 = int(row_count2*test_ratio)\n",
    "                    X, X_test = x_train[:split_point2], x_train[split_point2:]\n",
    "                    Y, Y_test = y_train[:split_point2], y_train[split_point2:]\n",
    "\n",
    "                    if(ii == 0):\n",
    "                        mdl = LinearRegression()\n",
    "                        mdl.fit(x_train, y_train)\n",
    "                    else: \n",
    "                        train_data = lightgbm.Dataset(X, label=Y)\n",
    "                        test_data = lightgbm.Dataset(X_test, label=Y_test)\n",
    "                        parameters = {'objective': 'regression','boosting': 'gbdt','metric': 'rmse','learning_rate': 0.1,'seed' : 42}\n",
    "                        mdl = lightgbm.train(parameters,train_data,valid_sets=test_data,num_boost_round=5000,early_stopping_rounds=100)\n",
    "                        #mdl = regressions[1]\n",
    "                    #y_pred = y_pred.append(mdl.predict(x_test2))\n",
    "                    ttemp = mdl.predict(x_test2)\n",
    "                    y_pred = np.append(y_pred, ttemp[0])\n",
    "                    #x_test3.c14 = y_pred2[0]\n",
    "                    #y_pred3 = mdl.predict(x_test3)\n",
    "                    #if(target == 'ZigZag'):\n",
    "                    #    next_zigzag2 = y_pred2\n",
    "                        #next_zigzag3 = y_pred3\n",
    "\n",
    "                    x.loc[x.shape[0]-1,'c15'] = y_test[y_test.index[0]+m]\n",
    "                    tempp2 = pd.DataFrame()\n",
    "                    tempp= x[x.shape[0]-1:]\n",
    "                    tempp = tempp.drop(\"c1\", axis=1)\n",
    "                    tempp2[['c1','c2','c3','c4','c5',\n",
    "                       'c6','c7','c8','c9','c10',\n",
    "                       'c11','c12','c13','c14']] = tempp\n",
    "                    tempp2['c15'] = np.nan\n",
    "                    #x= np.append(x,tempp2)\n",
    "                    x = pd.concat([x,tempp2] , ignore_index=True)\n",
    "                #-------------------\n",
    "\n",
    "\n",
    "                rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "                #-------\n",
    "                percent_error = (rmse/temp_error)*100\n",
    "                #results[forecast_name]= percent_error # mean\n",
    "                \n",
    "                if(target == 'ZigZag'):\n",
    "                    zigzag = y_pred\n",
    "                elif(target == 'ZigZag Length'):\n",
    "                    zigzaglength = y_pred\n",
    "                \n",
    "                #temp_y_test= y_test.to_numpy()\n",
    "                #percent_error = (abs((y_pred[1:])-(temp_y_test[:-1])) / abs((temp_y_test[1:])-(temp_y_test[:-1])) ) *100\n",
    "                #percent_error = [ x for x in percent_error if np.isfinite(x) ]\n",
    "                #percent_error = np.mean(percent_error)\n",
    "                \n",
    "                #percent_error= ((abs(y_test - y_pred) / abs(y_test))*100) \n",
    "                #percent_error = percent_error.mean()\n",
    "                \n",
    "                results[regression_names[ii]]= percent_error\n",
    "                print(\"RMSE = \" , rmse)\n",
    "                text = text + \"\\nRoot mean squared error for \"+ regression_names[ii] +' for '+ target +\" = \" + str(rmse) +\"\\n\"\n",
    "                text = text +'---------------------------------------------------------'\n",
    "                text = text + \"\\nPercent error for \"+ regression_names[ii] +' for '+ target +\" = \" + str(percent_error) +\"\\n\"\n",
    "                text = text +'---------------------------------------------------------'\n",
    "                       \n",
    "            \n",
    "            '''\n",
    "            # predict next value\n",
    "            next_new_data = y_data\n",
    "\n",
    "            if(target == ' ZigZag Value'):# Linear regression\n",
    "                #mdl = LinearRegression()\n",
    "                #mdl.fit(x_train, y_train)\n",
    "                y_pred2 = Forecast(next_new_data,forecast_name)\n",
    "                next_new_data = np.append(next_new_data, y_pred2)\n",
    "                y_pred3 = Forecast(next_new_data,forecast_name)\n",
    "            else: # Lightgbm\n",
    "                train_data = lightgbm.Dataset(X, label=Y)\n",
    "                test_data = lightgbm.Dataset(X_test, label=Y_test)\n",
    "                parameters = {'objective': 'regression','boosting': 'gbdt','metric': 'rmse','learning_rate': 0.1,'seed' : 42}\n",
    "                mdl = lightgbm.train(parameters,train_data,valid_sets=test_data,num_boost_round=5000,early_stopping_rounds=100)\n",
    "                #mdl = regressions[1]\n",
    "\n",
    "\n",
    "            if(target == ' ZigZag Value'):\n",
    "                next_zigzag2 = y_pred2\n",
    "                next_zigzag3 = y_pred3\n",
    "            text = text + \"\\n two Next prediction value for \"+ target +\" = \"+str(y_pred2)+\" and \"+ str(y_pred3)+\"\\n\"\n",
    "            text = text +'---------------------------------------------------------'\n",
    "            '''\n",
    "        file = open(files[j][:-4] +'_Log.txt', 'w')\n",
    "        file.write(text)\n",
    "        file.close()\n",
    "    \n",
    "    results['best'] = min(results.values[0][1:-1]) #------------MIN----------\n",
    "    result_file = result_file.append(results, ignore_index=True)\n",
    "\n",
    "# Create Result file\n",
    "#result_file = pd.DataFrame(columns = ['File_Name','LiteGBM', 'LR','AR','MA','ARMA','ARIMA','SARIMA','SES','HWES','Rank'])\n",
    "\n",
    "#result_file.File_Name = test_date\n",
    "#ai_file = ai_file.append(pd.Series(), ignore_index=True)\n",
    "#ai_file = ai_file.append(pd.Series(), ignore_index=True)\n",
    "#ai_file.ZigZag = zigzag\n",
    "#zigzaglength = zigzaglength.astype(int)\n",
    "#ai_file['ZigZag Length'] = zigzaglength\n",
    "\n",
    "result_file = result_file.sort_values(by=['best'], ascending=True)#saoodi\n",
    "result_file = result_file.drop(columns=['best'])\n",
    "result_file.to_csv('result.ai.csv', index=False)\n",
    "read_file = pd.read_csv ('result.ai.csv')\n",
    "read_file.to_excel ('result.ai.xlsx', index = None, header=True)\n",
    "\n",
    "\n",
    "#print(\"Waiting Time\")\n",
    "#prior_file_dict = file_dict\n",
    "#time.sleep(30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
